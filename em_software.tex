\chapter{Software in cryo-ET}\label{software}

Due to the rapid growth of cryo-ET, the software ecosystem as a whole is fragmented; conventions are either not established, or appear on a first-come-first-served basis, with little consensus or community discussion.
Meanwhile, the most established pipelines use big monolithic applications, developed with streamlined workflows in mind and little attention to code reusability.

\localtableofcontents

\section{Monolithic vs Modular: an academia paradox}

In academia, large publications with splashy headlines can make or break career paths, rewarding speed, competition, and secrecy; unfortunately, this is not conductive to the development of good software practices.

Researchers regularly develop ad hoc solutions, lacking the time and resources to release a maintainable tool, leading to software that can hardly be adapted even to similar problems.
These researchers are also typically PhD students that will soon move to a different group, work on different projects, and won't have any more time to dedicate to their old software.
It's rarely in their best interest to keep working on software that won't give them any further publications, so there's little incentive to begin development with modularity and maintainability in mind. 
All this leads to regular wheel-reinventing, and abandonware full of great ideas but hard to reuse in any capacity for future work.

In the rare success stories where software becomes adopted widely enough to achieve long term maintenance, it's usually in the form of inscrutable monolithic applications developed by a single group or person with little community collaboration on the development.
There are of course exceptions, but for young researchers it's generally a safer bet to go the "develop and publish" route than the "design and maintain" one; of course, most research developers struggle with this tension, wishing for their work to be reused and improved, but unable to allocate the time and resources required to do so.

\section{Metadata wrangling}

A common symptom of such an ecosystem is that significant time and effort is lost in dealing with metadata when setting up a cryo-ET data processing workflow.

Due to its history, cryo-ET has also inherited many tools and conventions from cryo-EM, even in cases where they had to be stretched thin in order to fit the needs of the new technique.
The existing de facto standard is arguably set by Relion, which in recent years has added explicit support for cryo-ET preprocessing and STA, encoding reconstruction and particles metadata in its STAR file format, which was previously only used for single particle analysis~\cite{zivanovBayesianApproachSingleparticle2022,burtImageProcessingPipeline2024}.
Several other formats exist for particle, alignment, and various other parameters and tilt-series metadata (Dynamo tables~\cite{castano-diezDynamoCatalogueGeometrical2017}, AreTomo alignments~\cite{zhengAreTomoIntegratedSoftware2022}, Warp spline grids~\cite{tegunovRealtimeCryoelectronMicroscopy2019}, etc.), and while some of them can be interchangeable, others are virtually impossible to convert between.

Currently, there are several attempts at intercommunication between software through converters and pipeline managers.
Scipion~\cite{delarosa-trevinScipionSoftwareFramework2016} is likely the most effective and prolific, but it fights an uphill battle, integrating wildly different software, languages and approaches that were never built to be collaborate.

\section{Human-in-the-loop}

These software ecosystem issues are especially problematic for cryo-ET, where custom workflows and unique solutions are routinely required, due the diverse nature of the samples and project goals.
Developing custom tools is often unfeasible for researchers new to the technique or who lack the necessary programming skills to delve deep in the code of the existing software.
Monolithic software suites offer user-friendly interfaces and automation --- some of their stronger selling points --- which can often get in the way of custom tool injections and human intervention.
On the flipside, tools that are standalone and single-purpose provide the flexibility to be used within any workflow, but may be difficult to integrate, especially without well-established conventions.

To move away from this limiting dichotomy, the cryo-ET community needs to move towards a human-in-the-loop (HILT) mentality, where automation and user-friendliness don't get in the way of customizability and control.
There are a few ways to push for such an ecosystem, but they mostly go against the aforementioned academia-machine:

\begin{enumerate}[noitemsep]
    \item build small-scoped, generalized and modular \textbf{libraries} to allow re-use by many, with a low barrier of entry
    \item develop on top of well-established generalized libraries (numpy, pandas, etc.), to minimize wheel-reinventing and lower the learning curve for new users
    \item engage the community to share maintenance responsibilities and institutional knowledge, in order to prevent abandonware and ensure continued development
    \item release code quickly and openly, without waiting for the lethargic publication industry, to encourage sharing and expedite exchange of ideas
    \item develop tools that others would want to use, not tools that only you need
\end{enumerate}

\section{Interactive visualisation}

In the context of this work, the push for HITL materialized as an interactive visualisation tool.


\section{Teamtomo}

TODO: talk about how *I* went about this

TODO: teamtomo, current goals and set up, lots of people involved ...

\begin{outline}
\1 importance of visualisation (human-in-the-loop)
    \2 issues caused by inability to look at data (wasted work, harder to form hypotheses)
    \2 importance of interactivity (not just looking, but picking, annotating, etc). Automation is great when it works, but in cryoet it's tricky and it often doesn't
        \3 problem of automation vs customizability
\1 annotation, segmentation, picking
    \2 especially hard in 3D, requires extra attention both in automated and manual procedures, and benefits especially from human-in-the-loop approach
    \2 existing software (not sure to what extent i should go here, or say to refer to the blik paper chapter)
\1 I'd like to have a general section about software practices, but not sure where
    \2 a case for user-friendliness (cryosparc > relion)
    \2 a case for open-source (relion > cryosparc)
    \2 a case for domain agnosticism (napari)
    \2 the benefits of modularity, "clean code", documentation, etc, to the research community
\end{outline}


\section{napari: powerful interactive visualisation}

This thesis was heavily influenced and shaped by my extended collaboration with the napari project~\cite{thenaparicommunityNapariMultidimensionalImage2024} and its core developers and community~\cite{thenaparicommunityCommunityNapari2024}, whose values and goals for the development of scientific software strongly align with mine.

The napari community aims to provide a fast, user-friendly, hackable and reusable library and application for the visualization and annotation of n-dimensional scientific imaging data.
It's built on top of the well-established and widespread libraries at the core of the scientific python ecosystem (such as numpy and pandas), in order to allow seamless interactive visualisation both programmatically and via graphical user interface.
Our committed effort to bridge many different imaging field to share knowledge and resources has resulted in a steady influx of new contributors and users from various backgrounds, who ensured napari remains user-friendly, hackable, and powerful.

Due to the distributed and collaborative nature of community-driven open-source development, it's a difficult (and futile) exercise to track down exactly who "authored" a specific features.
By delocalizing authorship, this often goes against the academia-machine, but it's also ensures continued maintenance by delocalizing responsibility.

\href{https://napari.org/}{napari.org}

\begin{outline}
\1 napari: interactive GUI (human-in-the-loop)
\1 development: my contributions as part of the thesis (didn't go in depth for blik paper)
    \2 architecture
    \2 slicing
    \2 vispy rendering
    \2 point/volume interactivity
    \2 plugins
\end{outline}
